{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_recall_curve, roc_auc_score, make_scorer, f1_score, recall_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    ")\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tianhan Baseline bagging + neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "numeric_df = numeric_df.drop(columns = [\"Unnamed: 0\"])\n",
    "X = numeric_df.drop(['FraudFound_P', 'PolicyNumber'], axis=1)\n",
    "y = numeric_df['FraudFound_P']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "def create_bagged_sets(X, y, n=10):\n",
    "    X_sets, y_sets = [], []\n",
    "    for _ in range(n):\n",
    "        idx = np.random.choice(len(X), size=len(X), replace=True)\n",
    "        X_sets.append(X.iloc[idx])\n",
    "        y_sets.append(y.iloc[idx])\n",
    "    return X_sets, y_sets\n",
    "\n",
    "X_sets, y_sets = create_bagged_sets(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 10 of each model\n",
    "def train_models(X_sets, y_sets, model_type):\n",
    "    models = []\n",
    "    for i in range(10):\n",
    "        if model_type == 'lr':\n",
    "            model = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "        elif model_type == 'dt':\n",
    "            model = DecisionTreeClassifier()\n",
    "        elif model_type == 'rf':\n",
    "            model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "        model.fit(X_sets[i], y_sets[i])\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "lr_models = train_models(X_sets, y_sets, 'lr')\n",
    "dt_models = train_models(X_sets, y_sets, 'dt')\n",
    "rf_models = train_models(X_sets, y_sets, 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate stacked prediction probabilities for each base model in the ensemble\n",
    "# For each model in the list, predict the probability of the positive class (fraud = 1)\n",
    "# The result is a 2D array where each column represents predictions from one model\n",
    "# This stacked array will be used as input features to the neural network ensemble\n",
    "\n",
    "def get_stacked_preds(models, X):\n",
    "    preds = [model.predict_proba(X)[:,1] for model in models]\n",
    "    return np.column_stack(preds)\n",
    "\n",
    "lr_preds_train = get_stacked_preds(lr_models, X_train)\n",
    "dt_preds_train = get_stacked_preds(dt_models, X_train)\n",
    "rf_preds_train = get_stacked_preds(rf_models, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple PyTorch neural network on the stacked predictions of base models\n",
    "# This NN learns to ensemble the outputs from 10 base models for a specific method (LR, DT, or RF)\n",
    "\n",
    "def train_nn_model(X_np, y_np, input_dim, epochs=10, lr=0.001):\n",
    "    model = SimpleNN(input_dim)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    dataset = TensorDataset(torch.tensor(X_np, dtype=torch.float32),\n",
    "                            torch.tensor(y_np.values, dtype=torch.float32).unsqueeze(1))\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(xb)\n",
    "            loss = criterion(output, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "lr_nn = train_nn_model(lr_preds_train, y_train, lr_preds_train.shape[1])\n",
    "dt_nn = train_nn_model(dt_preds_train, y_train, dt_preds_train.shape[1])\n",
    "rf_nn = train_nn_model(rf_preds_train, y_train, rf_preds_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the output predictions from a trained PyTorch neural network\n",
    "# This is used to obtain ensemble predictions from each of the LR, DT, RF ensembles\n",
    "# These outputs will serve as input features to the final-level ensemble model\n",
    "\n",
    "def get_nn_output(model, X_np):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor(X_np, dtype=torch.float32)\n",
    "        return model(input_tensor).numpy()\n",
    "\n",
    "lr_out_train = get_nn_output(lr_nn, lr_preds_train)\n",
    "dt_out_train = get_nn_output(dt_nn, dt_preds_train)\n",
    "rf_out_train = get_nn_output(rf_nn, rf_preds_train)\n",
    "\n",
    "stacked_train = np.hstack([lr_out_train, dt_out_train, rf_out_train])\n",
    "final_nn = train_nn_model(stacked_train, y_train, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      2899\n",
      "           1       0.33      0.09      0.14       185\n",
      "\n",
      "    accuracy                           0.93      3084\n",
      "   macro avg       0.64      0.54      0.55      3084\n",
      "weighted avg       0.91      0.93      0.92      3084\n",
      "\n",
      "ROC AUC Score: 0.5558515051788595\n"
     ]
    }
   ],
   "source": [
    "# Stacked test preds\n",
    "lr_preds_test = get_stacked_preds(lr_models, X_test)\n",
    "dt_preds_test = get_stacked_preds(dt_models, X_test)\n",
    "rf_preds_test = get_stacked_preds(rf_models, X_test)\n",
    "\n",
    "lr_out_test = get_nn_output(lr_nn, lr_preds_test)\n",
    "dt_out_test = get_nn_output(dt_nn, dt_preds_test)\n",
    "rf_out_test = get_nn_output(rf_nn, rf_preds_test)\n",
    "\n",
    "stacked_test = np.hstack([lr_out_test, dt_out_test, rf_out_test])\n",
    "final_preds = get_nn_output(final_nn, stacked_test)\n",
    "final_preds_binary = (final_preds > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "print(classification_report(y_test, final_preds_binary))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning of models\n",
    "Here, we tried hyperparameter tuning for number of hiddne units, epochs, learning rate, dropout rate\n",
    "Class imbalance handling using pos_weight in loss function\n",
    "Threshold optimization instead of using a fixed 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(X_np, y_np, input_dim, epochs=20, lr=0.001, hidden_dim=10, dropout=0.0):\n",
    "    class TunedNN(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, dropout):\n",
    "            super().__init__()\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(hidden_dim, 1)  # No Sigmoid here\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "\n",
    "    model = TunedNN(input_dim, hidden_dim, dropout)\n",
    "\n",
    "    # Handle class imbalance\n",
    "    fraud_ratio = y_np.value_counts()[0] / y_np.value_counts()[1]\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([fraud_ratio], dtype=torch.float32))\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(X_np, dtype=torch.float32),\n",
    "        torch.tensor(y_np.values, dtype=torch.float32).unsqueeze(1)\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(xb)\n",
    "            loss = criterion(output, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_thresholds(y_true, y_prob):\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0.5\n",
    "    best_metrics = {}\n",
    "\n",
    "    for t in np.arange(0.05, 0.95, 0.01):\n",
    "        y_pred = (y_prob > t).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "        if f1 > best_f1 or (f1 == best_f1 and recall > best_metrics.get(\"recall\", 0)):\n",
    "            best_f1 = f1\n",
    "            best_threshold = t\n",
    "            best_metrics = {\n",
    "                \"threshold\": t,\n",
    "                \"f1\": f1,\n",
    "                \"recall\": recall,\n",
    "                \"auc\": auc,\n",
    "                \"confusion_matrix\": confusion_matrix(y_true, y_pred)\n",
    "            }\n",
    "\n",
    "    return best_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.05\n",
      "F1 Score: 0.2204\n",
      "Recall: 0.2216\n",
      "ROC AUC: 0.5559\n",
      "Confusion Matrix:\n",
      "[[2753  146]\n",
      " [ 144   41]]\n"
     ]
    }
   ],
   "source": [
    "# Get outputs from test set\n",
    "lr_preds_test = get_stacked_preds(lr_models, X_test)\n",
    "dt_preds_test = get_stacked_preds(dt_models, X_test)\n",
    "rf_preds_test = get_stacked_preds(rf_models, X_test)\n",
    "\n",
    "lr_out_test = get_nn_output(lr_nn, lr_preds_test)\n",
    "dt_out_test = get_nn_output(dt_nn, dt_preds_test)\n",
    "rf_out_test = get_nn_output(rf_nn, rf_preds_test)\n",
    "\n",
    "stacked_test = np.hstack([lr_out_test, dt_out_test, rf_out_test])\n",
    "final_test_probs = get_nn_output(final_nn, stacked_test)\n",
    "\n",
    "# Tune threshold and evaluate\n",
    "best_metrics = evaluate_thresholds(y_test, final_test_probs)\n",
    "\n",
    "print(f\"Best Threshold: {best_metrics['threshold']:.2f}\")\n",
    "print(f\"F1 Score: {best_metrics['f1']:.4f}\")\n",
    "print(f\"Recall: {best_metrics['recall']:.4f}\")\n",
    "print(f\"ROC AUC: {best_metrics['auc']:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(best_metrics[\"confusion_matrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proceed to do grid search\n",
    "# Define the search space\n",
    "param_grid = {\n",
    "    'hidden_dim': [8, 16, 32],\n",
    "    'dropout': [0.0, 0.2, 0.5],\n",
    "    'lr': [0.001, 0.0005],\n",
    "    'epochs': [20, 40]\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "param_combos = list(product(\n",
    "    param_grid['hidden_dim'],\n",
    "    param_grid['dropout'],\n",
    "    param_grid['lr'],\n",
    "    param_grid['epochs']\n",
    "))\n",
    "\n",
    "best_result = {\n",
    "    'f1': 0,\n",
    "    'recall': 0,\n",
    "    'auc': 0,\n",
    "    'params': None,\n",
    "    'threshold': 0.5,\n",
    "    'confusion_matrix': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_output_finetuning(model, X_np):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor(X_np, dtype=torch.float32)\n",
    "        logits = model(input_tensor)\n",
    "        probs = torch.sigmoid(logits)  # Manual sigmoid\n",
    "        return probs.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_dim, dropout, lr, epochs in param_combos:\n",
    "    # Train NN on training set\n",
    "    model = train_nn_model(\n",
    "        stacked_train, y_train,\n",
    "        input_dim=3,\n",
    "        hidden_dim=hidden_dim,\n",
    "        dropout=dropout,\n",
    "        lr=lr,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    # Get probabilities on test set\n",
    "    final_test_probs = get_nn_output_finetuning(model, stacked_test)\n",
    "\n",
    "    # Evaluate at best threshold\n",
    "    metrics = evaluate_thresholds(y_test, final_test_probs)\n",
    "\n",
    "    if (metrics['f1'] > best_result['f1']) or \\\n",
    "       (metrics['f1'] == best_result['f1'] and metrics['recall'] > best_result['recall']):\n",
    "        best_result.update({\n",
    "            'f1': metrics['f1'],\n",
    "            'recall': metrics['recall'],\n",
    "            'auc': metrics['auc'],\n",
    "            'params': {\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'dropout': dropout,\n",
    "                'lr': lr,\n",
    "                'epochs': epochs\n",
    "            },\n",
    "            'threshold': metrics['threshold'],\n",
    "            'confusion_matrix': metrics['confusion_matrix']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'hidden_dim': 8, 'dropout': 0.0, 'lr': 0.0005, 'epochs': 20}\n",
      "Optimal Threshold: 0.24\n",
      "F1 Score: 0.2729\n",
      "Recall: 0.4757\n",
      "ROC AUC: 0.7369\n",
      "Confusion Matrix:\n",
      "[[2527  372]\n",
      " [  97   88]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters:\")\n",
    "print(best_result['params'])\n",
    "print(f\"Optimal Threshold: {best_result['threshold']:.2f}\")\n",
    "print(f\"F1 Score: {best_result['f1']:.4f}\")\n",
    "print(f\"Recall: {best_result['recall']:.4f}\")\n",
    "print(f\"ROC AUC: {best_result['auc']:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(best_result['confusion_matrix'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_nn_best = train_nn_model(\n",
    "    stacked_train, y_train,\n",
    "    input_dim=3,\n",
    "    hidden_dim=8,\n",
    "    dropout=0.2,\n",
    "    lr=0.001,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "final_probs = get_nn_output_finetuning(final_nn_best, stacked_test)\n",
    "\n",
    "final_preds = (final_probs > 0.07).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      2899\n",
      "           1       0.21      0.24      0.23       185\n",
      "\n",
      "    accuracy                           0.90      3084\n",
      "   macro avg       0.58      0.59      0.59      3084\n",
      "weighted avg       0.91      0.90      0.90      3084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2733  166]\n",
      " [ 140   45]]\n",
      "ROC AUC: 0.8220747135545343\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, final_preds))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, final_preds))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, final_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ashley's Voting and Stacking model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "numeric_df = numeric_df.drop(columns = [\"Unnamed: 0\"])\n",
    "X = numeric_df.drop(['FraudFound_P', 'PolicyNumber'], axis=1)\n",
    "y = numeric_df['FraudFound_P']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80-20 split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "df_smote = pd.concat([X_train_oversampled, y_train_oversampled], axis = 1)\n",
    "X_smote = df_smote.drop(columns=\"FraudFound_P\")\n",
    "y_smote = df_smote[\"FraudFound_P\"]\n",
    "\n",
    "df_train_smote = pd.concat([X_smote, y_smote], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>AccidentArea</th>\n",
       "      <th>MonthClaimed</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>DayOfWeekClaimed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fault</th>\n",
       "      <th>...</th>\n",
       "      <th>BasePolicy</th>\n",
       "      <th>UnusualDeductible</th>\n",
       "      <th>ClaimsPerAgent</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>PriceToAgeRatio</th>\n",
       "      <th>PriceToAgeRatio_Capped</th>\n",
       "      <th>HighRiskVehicleFlag</th>\n",
       "      <th>ClaimAmountRisk</th>\n",
       "      <th>DaysBetween</th>\n",
       "      <th>ClaimProcessingTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23217</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117783</td>\n",
       "      <td>0.117783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23218</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326930</td>\n",
       "      <td>0.326930</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23219</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320814</td>\n",
       "      <td>0.320814</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23220</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.315845</td>\n",
       "      <td>0.315845</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23221</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.287649</td>\n",
       "      <td>0.287649</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23222 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  WeekOfMonth  DayOfWeek  AccidentArea  MonthClaimed  \\\n",
       "0          5            2          5             1             5   \n",
       "1         11            4          6             1            11   \n",
       "2          3            1          4             1             3   \n",
       "3          4            4          7             1             4   \n",
       "4          3            5          3             1             3   \n",
       "...      ...          ...        ...           ...           ...   \n",
       "23217      1            2          5             0             2   \n",
       "23218      4            3          5             0             4   \n",
       "23219      3            3          4             1             4   \n",
       "23220      5            3          2             1             5   \n",
       "23221     10            2          5             0            11   \n",
       "\n",
       "       WeekOfMonthClaimed  DayOfWeekClaimed  Sex  Age  Fault  ...  BasePolicy  \\\n",
       "0                       4                 2    1   42      0  ...           1   \n",
       "1                       4                 1    1   33      1  ...           1   \n",
       "2                       3                 4    0   40      0  ...           2   \n",
       "3                       4                 1    0   29      0  ...           2   \n",
       "4                       5                 3    1   72      0  ...           1   \n",
       "...                   ...               ...  ...  ...    ...  ...         ...   \n",
       "23217                   2                 2    1   52      0  ...           3   \n",
       "23218                   3                 2    0   33      0  ...           2   \n",
       "23219                   1                 2    0   30      0  ...           3   \n",
       "23220                   3                 4    1   39      0  ...           1   \n",
       "23221                   1                 3    1   30      0  ...           2   \n",
       "\n",
       "       UnusualDeductible  ClaimsPerAgent  MaritalStatus  PriceToAgeRatio  \\\n",
       "0                      0           15179              1         0.251314   \n",
       "1                      0           15179              1         0.251314   \n",
       "2                      0           15179              1         0.251314   \n",
       "3                      0           15179              0         0.251314   \n",
       "4                      0           15179              1         0.223144   \n",
       "...                  ...             ...            ...              ...   \n",
       "23217                  0           15179              1         0.117783   \n",
       "23218                  0           15179              0         0.326930   \n",
       "23219                  0           15179              0         0.320814   \n",
       "23220                  0           15179              1         0.315845   \n",
       "23221                  0           15179              1         0.287649   \n",
       "\n",
       "       PriceToAgeRatio_Capped  HighRiskVehicleFlag  ClaimAmountRisk  \\\n",
       "0                    0.251314                    0                1   \n",
       "1                    0.251314                    0                1   \n",
       "2                    0.251314                    0                1   \n",
       "3                    0.251314                    0                4   \n",
       "4                    0.223144                    0                2   \n",
       "...                       ...                  ...              ...   \n",
       "23217                0.117783                    0                0   \n",
       "23218                0.326930                    0                1   \n",
       "23219                0.320814                    0                5   \n",
       "23220                0.315845                    0                3   \n",
       "23221                0.287649                    0                1   \n",
       "\n",
       "       DaysBetween  ClaimProcessingTime  \n",
       "0                1                  376  \n",
       "1                1                  360  \n",
       "2                1                  379  \n",
       "3                1                  359  \n",
       "4                1                  365  \n",
       "...            ...                  ...  \n",
       "23217            1                  377  \n",
       "23218            1                  361  \n",
       "23219            1                  372  \n",
       "23220            1                  368  \n",
       "23221            1                  378  \n",
       "\n",
       "[23222 rows x 38 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11611, number of negative: 11611\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1098\n",
      "[LightGBM] [Info] Number of data points in the train set: 23222, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "==== Voting Classifier ====\n",
      "Accuracy: 0.8119\n",
      "Confusion Matrix:\n",
      "[[2401  484]\n",
      " [  96  103]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      2885\n",
      "           1       0.18      0.52      0.26       199\n",
      "\n",
      "    accuracy                           0.81      3084\n",
      "   macro avg       0.57      0.67      0.58      3084\n",
      "weighted avg       0.91      0.81      0.85      3084\n",
      "\n",
      "ROC AUC Score: 0.7987\n"
     ]
    }
   ],
   "source": [
    "calibrated_rf = CalibratedClassifierCV(\n",
    "    RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=36),\n",
    "    method='isotonic', cv=3\n",
    ")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, class_weight=\"balanced\"))),\n",
    "        ('rf', calibrated_rf),\n",
    "        ('xgb', xgb.XGBClassifier(n_estimators=100, eval_metric=\"logloss\", random_state=42, scale_pos_weight=12)),\n",
    "        ('lgb', lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "    ],\n",
    "    voting='soft'  # Change to 'hard' for majority voting\n",
    ")\n",
    "\n",
    "# Train voting classifier\n",
    "voting_clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# Predict\n",
    "y_proba = voting_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_voting = (y_proba >= 0.30).astype(int)\n",
    "# Evaluate\n",
    "print(\"==== Voting Classifier ====\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_voting):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_voting))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11611, number of negative: 11611\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1098\n",
      "[LightGBM] [Info] Number of data points in the train set: 23222, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best Threshold by F1: 0.27, F1-score: 0.266\n",
      "ROC AUC Score: 0.7987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.802     0.877      2885\n",
      "           1      0.172     0.593     0.266       199\n",
      "\n",
      "    accuracy                          0.789      3084\n",
      "   macro avg      0.569     0.698     0.571      3084\n",
      "weighted avg      0.915     0.789     0.837      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calibrated_rf = CalibratedClassifierCV(\n",
    "    RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=36),\n",
    "    method='isotonic', cv=3\n",
    ")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, class_weight=\"balanced\"))),\n",
    "        ('rf', calibrated_rf),\n",
    "        ('xgb', xgb.XGBClassifier(n_estimators=100, eval_metric=\"logloss\", random_state=42, scale_pos_weight=12)),\n",
    "        ('lgb', lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "    ],\n",
    "    voting='soft'  # Change to 'hard' for majority voting\n",
    ")\n",
    "\n",
    "# Train voting classifier\n",
    "voting_clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# Predict\n",
    "y_proba = voting_clf.predict_proba(X_test)[:, 1]\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, roc_auc_score\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-6)\n",
    "best_threshold = thresholds[f1_scores.argmax()]\n",
    "print(f\"Best Threshold by F1: {best_threshold:.2f}, F1-score: {f1_scores.max():.3f}\")\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Use the new threshold\n",
    "y_pred_best = (y_proba >= best_threshold).astype(int)\n",
    "print(classification_report(y_test, y_pred_best, digits=3))\n",
    "\n",
    "# Model Update Summary (Voting Classifier)\n",
    "\n",
    "# - Applied class balancing techniques: 'class_weight' and 'scale_pos_weight' for base models\n",
    "# - Calibrated the Random Forest classifier using isotonic regression for better probability estimates\n",
    "# - Used 'soft' voting to average predicted probabilities across models\n",
    "# - Tuned the classification threshold using precision-recall curve to optimize for F1-score of fraud class (label=1)\n",
    "# ➤ These changes aim to improve fraud detection performance, especially recall and F1, on the imbalanced test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [21:32:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11611, number of negative: 11611\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1098\n",
      "[LightGBM] [Info] Number of data points in the train set: 23222, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best F1-score (fraud class): 0.24177656229698838\n",
      "Best parameters:\n",
      "{'voting__xgb__n_estimators': 200, 'voting__xgb__learning_rate': 0.01, 'voting__rf__n_estimators': 100, 'voting__rf__max_depth': 10, 'voting__lgb__n_estimators': 200, 'voting__lgb__learning_rate': 0.01}\n",
      "ROC AUC Score: 0.7987\n",
      "[[2129  756]\n",
      " [  66  133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.970     0.738     0.838      2885\n",
      "           1      0.150     0.668     0.244       199\n",
      "\n",
      "    accuracy                          0.733      3084\n",
      "   macro avg      0.560     0.703     0.541      3084\n",
      "weighted avg      0.917     0.733     0.800      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with StandardScaler\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# XGBoost with imbalance handling\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=12, random_state=42)\n",
    "\n",
    "# LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_model),\n",
    "        ('rf', rf_model),\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgb', lgb_model)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('voting', voting_clf)\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'voting__rf__n_estimators': [100, 200, 300],\n",
    "    'voting__rf__max_depth': [5, 10, None],\n",
    "    'voting__xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'voting__xgb__n_estimators': [100, 200],\n",
    "    'voting__lgb__n_estimators': [100, 200],\n",
    "    'voting__lgb__learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring=scorer,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model results\n",
    "print(\"Best F1-score (fraud class):\", random_search.best_score_)\n",
    "print(\"Best parameters:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "y_pred_best = random_search.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold by F1: 0.11, F1-score: 0.255\n",
      "ROC AUC Score: 0.7733\n",
      "==== Final Stacking Classifier with CV + SMOTE ====\n",
      "Confusion Matrix:\n",
      "[[2496  389]\n",
      " [ 122   77]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.953     0.865     0.907      2885\n",
      "           1      0.165     0.387     0.232       199\n",
      "\n",
      "    accuracy                          0.834      3084\n",
      "   macro avg      0.559     0.626     0.569      3084\n",
      "weighted avg      0.903     0.834     0.864      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Base models with class weightings\n",
    "base_models = [\n",
    "    ('lr', make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, class_weight=\"balanced\"))),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=36)),\n",
    "    ('xgb', xgb.XGBClassifier(n_estimators=100, eval_metric=\"logloss\", random_state=42, scale_pos_weight=12)),\n",
    "    ('lgb', lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "]\n",
    "\n",
    "# Stronger meta model\n",
    "meta_model = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Stacking classifier (no oversampled data used here!)\n",
    "stack_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    passthrough=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Full pipeline with SMOTE\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('stacking', stack_clf)\n",
    "])\n",
    "\n",
    "# StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validated predictions on training data (simulate test set)\n",
    "y_proba_cv = cross_val_predict(pipeline, X_train, y_train, cv=skf, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "\n",
    "# Find best threshold\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_proba_cv)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-6)\n",
    "best_threshold = thresholds[f1_scores.argmax()]\n",
    "print(f\"Best Threshold by F1: {best_threshold:.2f}, F1-score: {f1_scores.max():.3f}\")\n",
    "\n",
    "# Refit final model on full training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on real test set\n",
    "y_proba_test = pipeline.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (y_proba_test >= best_threshold).astype(int)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba_test)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "print(\"==== Final Stacking Classifier with CV + SMOTE ====\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, digits=3))\n",
    "\n",
    "# Model Update Summary (Stacking Classifier)\n",
    "# - Replaced training on oversampled data with StratifiedKFold cross-validation\n",
    "# - Applied SMOTE inside each fold using a pipeline to avoid data leakage\n",
    "# - Used a stronger meta-model (Random Forest instead of Logistic Regression)\n",
    "# - Tuned the decision threshold based on the best F1-score from precision-recall curve\n",
    "# These changes aim to improve fraud class (label=1) recall and F1-score while keeping evaluation realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after undersampling:\n",
      "FraudFound_P\n",
      "0    724\n",
      "1    724\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Performance on undersampled dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.65      0.78      2885\n",
      "           1       0.15      0.87      0.25       199\n",
      "\n",
      "    accuracy                           0.66      3084\n",
      "   macro avg       0.57      0.76      0.51      3084\n",
      "weighted avg       0.93      0.66      0.75      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming numeric_df is your dataset (already loaded)\n",
    "# Prepare the data\n",
    "X = numeric_df.drop(['FraudFound_P', 'PolicyNumber'], axis=1)\n",
    "y = numeric_df['FraudFound_P']\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define RandomUnderSampler\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Apply RandomUnderSampler to the training data to reduce the majority class size\n",
    "X_train_under, y_train_under = under_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(\"Class distribution after undersampling:\")\n",
    "print(pd.Series(y_train_under).value_counts())\n",
    "\n",
    "# Train and evaluate a RandomForest model on the original dataset (without undersampling)\n",
    "clf_original = RandomForestClassifier(random_state=42)\n",
    "clf_original.fit(X_train, y_train)\n",
    "y_pred_original = clf_original.predict(X_test)\n",
    "\n",
    "# Train and evaluate a RandomForest model on the undersampled dataset\n",
    "clf_under = RandomForestClassifier(random_state=42)\n",
    "clf_under.fit(X_train_under, y_train_under)\n",
    "y_pred_under = clf_under.predict(X_test)\n",
    "\n",
    "print(\"\\nPerformance on undersampled dataset:\")\n",
    "print(classification_report(y_test, y_pred_under, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
