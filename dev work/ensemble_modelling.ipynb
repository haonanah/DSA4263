{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model evaluation and metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_recall_curve, roc_auc_score, make_scorer, f1_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict, RandomizedSearchCV\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    ")\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Calibration\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tianhan bagging + neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "X = numeric_df.drop(['FraudFound_P', 'PolicyNumber'], axis=1)\n",
    "y = numeric_df['FraudFound_P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ashley's Voting and Stacking model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "numeric_df = numeric_df.drop(columns = [\"Unnamed: 0\"])\n",
    "X = numeric_df.drop(['FraudFound_P', 'PolicyNumber'], axis=1)\n",
    "y = numeric_df['FraudFound_P']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80-20 split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_oversampled, y_train_oversampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "df_smote = pd.concat([X_train_oversampled, y_train_oversampled], axis = 1)\n",
    "X_smote = df_smote.drop(columns=\"FraudFound_P\")\n",
    "y_smote = df_smote[\"FraudFound_P\"]\n",
    "\n",
    "df_train_smote = pd.concat([X_smote, y_smote], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>AccidentArea</th>\n",
       "      <th>MonthClaimed</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>DayOfWeekClaimed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fault</th>\n",
       "      <th>...</th>\n",
       "      <th>BasePolicy</th>\n",
       "      <th>UnusualDeductible</th>\n",
       "      <th>ClaimsPerAgent</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>PriceToAgeRatio</th>\n",
       "      <th>PriceToAgeRatio_Capped</th>\n",
       "      <th>HighRiskVehicleFlag</th>\n",
       "      <th>ClaimAmountRisk</th>\n",
       "      <th>DaysBetween</th>\n",
       "      <th>ClaimProcessingTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23217</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117783</td>\n",
       "      <td>0.117783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23218</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326930</td>\n",
       "      <td>0.326930</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23219</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320814</td>\n",
       "      <td>0.320814</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23220</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.315845</td>\n",
       "      <td>0.315845</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23221</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.287649</td>\n",
       "      <td>0.287649</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23222 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  WeekOfMonth  DayOfWeek  AccidentArea  MonthClaimed  \\\n",
       "0          5            2          5             1             5   \n",
       "1         11            4          6             1            11   \n",
       "2          3            1          4             1             3   \n",
       "3          4            4          7             1             4   \n",
       "4          3            5          3             1             3   \n",
       "...      ...          ...        ...           ...           ...   \n",
       "23217      1            2          5             0             2   \n",
       "23218      4            3          5             0             4   \n",
       "23219      3            3          4             1             4   \n",
       "23220      5            3          2             1             5   \n",
       "23221     10            2          5             0            11   \n",
       "\n",
       "       WeekOfMonthClaimed  DayOfWeekClaimed  Sex  Age  Fault  ...  BasePolicy  \\\n",
       "0                       4                 2    1   42      0  ...           1   \n",
       "1                       4                 1    1   33      1  ...           1   \n",
       "2                       3                 4    0   40      0  ...           2   \n",
       "3                       4                 1    0   29      0  ...           2   \n",
       "4                       5                 3    1   72      0  ...           1   \n",
       "...                   ...               ...  ...  ...    ...  ...         ...   \n",
       "23217                   2                 2    1   52      0  ...           3   \n",
       "23218                   3                 2    0   33      0  ...           2   \n",
       "23219                   1                 2    0   30      0  ...           3   \n",
       "23220                   3                 4    1   39      0  ...           1   \n",
       "23221                   1                 3    1   30      0  ...           2   \n",
       "\n",
       "       UnusualDeductible  ClaimsPerAgent  MaritalStatus  PriceToAgeRatio  \\\n",
       "0                      0           15179              1         0.251314   \n",
       "1                      0           15179              1         0.251314   \n",
       "2                      0           15179              1         0.251314   \n",
       "3                      0           15179              0         0.251314   \n",
       "4                      0           15179              1         0.223144   \n",
       "...                  ...             ...            ...              ...   \n",
       "23217                  0           15179              1         0.117783   \n",
       "23218                  0           15179              0         0.326930   \n",
       "23219                  0           15179              0         0.320814   \n",
       "23220                  0           15179              1         0.315845   \n",
       "23221                  0           15179              1         0.287649   \n",
       "\n",
       "       PriceToAgeRatio_Capped  HighRiskVehicleFlag  ClaimAmountRisk  \\\n",
       "0                    0.251314                    0                1   \n",
       "1                    0.251314                    0                1   \n",
       "2                    0.251314                    0                1   \n",
       "3                    0.251314                    0                4   \n",
       "4                    0.223144                    0                2   \n",
       "...                       ...                  ...              ...   \n",
       "23217                0.117783                    0                0   \n",
       "23218                0.326930                    0                1   \n",
       "23219                0.320814                    0                5   \n",
       "23220                0.315845                    0                3   \n",
       "23221                0.287649                    0                1   \n",
       "\n",
       "       DaysBetween  ClaimProcessingTime  \n",
       "0                1                  376  \n",
       "1                1                  360  \n",
       "2                1                  379  \n",
       "3                1                  359  \n",
       "4                1                  365  \n",
       "...            ...                  ...  \n",
       "23217            1                  377  \n",
       "23218            1                  361  \n",
       "23219            1                  372  \n",
       "23220            1                  368  \n",
       "23221            1                  378  \n",
       "\n",
       "[23222 rows x 38 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11611, number of negative: 11611\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1098\n",
      "[LightGBM] [Info] Number of data points in the train set: 23222, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "==== Voting Classifier ====\n",
      "Accuracy: 0.8119\n",
      "Confusion Matrix:\n",
      "[[2401  484]\n",
      " [  96  103]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      2885\n",
      "           1       0.18      0.52      0.26       199\n",
      "\n",
      "    accuracy                           0.81      3084\n",
      "   macro avg       0.57      0.67      0.58      3084\n",
      "weighted avg       0.91      0.81      0.85      3084\n",
      "\n",
      "ROC AUC Score: 0.7987\n"
     ]
    }
   ],
   "source": [
    "calibrated_rf = CalibratedClassifierCV(\n",
    "    RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=36),\n",
    "    method='isotonic', cv=3\n",
    ")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, class_weight=\"balanced\"))),\n",
    "        ('rf', calibrated_rf),\n",
    "        ('xgb', xgb.XGBClassifier(n_estimators=100, eval_metric=\"logloss\", random_state=42, scale_pos_weight=12)),\n",
    "        ('lgb', lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "    ],\n",
    "    voting='soft'  # Change to 'hard' for majority voting\n",
    ")\n",
    "\n",
    "# Train voting classifier\n",
    "voting_clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# Predict\n",
    "y_proba = voting_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_voting = (y_proba >= 0.30).astype(int)\n",
    "# Evaluate\n",
    "print(\"==== Voting Classifier ====\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_voting):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_voting))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11611, number of negative: 11611\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1098\n",
      "[LightGBM] [Info] Number of data points in the train set: 23222, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best Threshold by F1: 0.27, F1-score: 0.266\n",
      "ROC AUC Score: 0.7987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.802     0.877      2885\n",
      "           1      0.172     0.593     0.266       199\n",
      "\n",
      "    accuracy                          0.789      3084\n",
      "   macro avg      0.569     0.698     0.571      3084\n",
      "weighted avg      0.915     0.789     0.837      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calibrated_rf = CalibratedClassifierCV(\n",
    "    RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=36),\n",
    "    method='isotonic', cv=3\n",
    ")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, class_weight=\"balanced\"))),\n",
    "        ('rf', calibrated_rf),\n",
    "        ('xgb', xgb.XGBClassifier(n_estimators=100, eval_metric=\"logloss\", random_state=42, scale_pos_weight=12)),\n",
    "        ('lgb', lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "    ],\n",
    "    voting='soft'  # Change to 'hard' for majority voting\n",
    ")\n",
    "\n",
    "# Train voting classifier\n",
    "voting_clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# Predict\n",
    "y_proba = voting_clf.predict_proba(X_test)[:, 1]\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, roc_auc_score\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-6)\n",
    "best_threshold = thresholds[f1_scores.argmax()]\n",
    "print(f\"Best Threshold by F1: {best_threshold:.2f}, F1-score: {f1_scores.max():.3f}\")\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Use the new threshold\n",
    "y_pred_best = (y_proba >= best_threshold).astype(int)\n",
    "print(classification_report(y_test, y_pred_best, digits=3))\n",
    "\n",
    "# Model Update Summary (Voting Classifier)\n",
    "\n",
    "# - Applied class balancing techniques: 'class_weight' and 'scale_pos_weight' for base models\n",
    "# - Calibrated the Random Forest classifier using isotonic regression for better probability estimates\n",
    "# - Used 'soft' voting to average predicted probabilities across models\n",
    "# - Tuned the classification threshold using precision-recall curve to optimize for F1-score of fraud class (label=1)\n",
    "# ➤ These changes aim to improve fraud detection performance, especially recall and F1, on the imbalanced test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [21:32:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11611, number of negative: 11611\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1098\n",
      "[LightGBM] [Info] Number of data points in the train set: 23222, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best F1-score (fraud class): 0.24177656229698838\n",
      "Best parameters:\n",
      "{'voting__xgb__n_estimators': 200, 'voting__xgb__learning_rate': 0.01, 'voting__rf__n_estimators': 100, 'voting__rf__max_depth': 10, 'voting__lgb__n_estimators': 200, 'voting__lgb__learning_rate': 0.01}\n",
      "ROC AUC Score: 0.7987\n",
      "[[2129  756]\n",
      " [  66  133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.970     0.738     0.838      2885\n",
      "           1      0.150     0.668     0.244       199\n",
      "\n",
      "    accuracy                          0.733      3084\n",
      "   macro avg      0.560     0.703     0.541      3084\n",
      "weighted avg      0.917     0.733     0.800      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with StandardScaler\n",
    "lr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# XGBoost with imbalance handling\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=12, random_state=42)\n",
    "\n",
    "# LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_model),\n",
    "        ('rf', rf_model),\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgb', lgb_model)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('voting', voting_clf)\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'voting__rf__n_estimators': [100, 200, 300],\n",
    "    'voting__rf__max_depth': [5, 10, None],\n",
    "    'voting__xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'voting__xgb__n_estimators': [100, 200],\n",
    "    'voting__lgb__n_estimators': [100, 200],\n",
    "    'voting__lgb__learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring=scorer,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model results\n",
    "print(\"Best F1-score (fraud class):\", random_search.best_score_)\n",
    "print(\"Best parameters:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "y_pred_best = random_search.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold by F1: 0.11, F1-score: 0.255\n",
      "ROC AUC Score: 0.7733\n",
      "==== Final Stacking Classifier with CV + SMOTE ====\n",
      "Confusion Matrix:\n",
      "[[2496  389]\n",
      " [ 122   77]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.953     0.865     0.907      2885\n",
      "           1      0.165     0.387     0.232       199\n",
      "\n",
      "    accuracy                          0.834      3084\n",
      "   macro avg      0.559     0.626     0.569      3084\n",
      "weighted avg      0.903     0.834     0.864      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Base models with class weightings\n",
    "base_models = [\n",
    "    ('lr', make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, class_weight=\"balanced\"))),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=36)),\n",
    "    ('xgb', xgb.XGBClassifier(n_estimators=100, eval_metric=\"logloss\", random_state=42, scale_pos_weight=12)),\n",
    "    ('lgb', lgb.LGBMClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "]\n",
    "\n",
    "# Stronger meta model\n",
    "meta_model = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Stacking classifier (no oversampled data used here!)\n",
    "stack_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    passthrough=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Full pipeline with SMOTE\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('stacking', stack_clf)\n",
    "])\n",
    "\n",
    "# StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validated predictions on training data (simulate test set)\n",
    "y_proba_cv = cross_val_predict(pipeline, X_train, y_train, cv=skf, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "\n",
    "# Find best threshold\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_proba_cv)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-6)\n",
    "best_threshold = thresholds[f1_scores.argmax()]\n",
    "print(f\"Best Threshold by F1: {best_threshold:.2f}, F1-score: {f1_scores.max():.3f}\")\n",
    "\n",
    "# Refit final model on full training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on real test set\n",
    "y_proba_test = pipeline.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (y_proba_test >= best_threshold).astype(int)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba_test)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "print(\"==== Final Stacking Classifier with CV + SMOTE ====\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, digits=3))\n",
    "\n",
    "# Model Update Summary (Stacking Classifier)\n",
    "# - Replaced training on oversampled data with StratifiedKFold cross-validation\n",
    "# - Applied SMOTE inside each fold using a pipeline to avoid data leakage\n",
    "# - Used a stronger meta-model (Random Forest instead of Logistic Regression)\n",
    "# - Tuned the decision threshold based on the best F1-score from precision-recall curve\n",
    "# These changes aim to improve fraud class (label=1) recall and F1-score while keeping evaluation realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after undersampling:\n",
      "FraudFound_P\n",
      "0    724\n",
      "1    724\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Performance on undersampled dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.65      0.78      2885\n",
      "           1       0.15      0.87      0.25       199\n",
      "\n",
      "    accuracy                           0.66      3084\n",
      "   macro avg       0.57      0.76      0.51      3084\n",
      "weighted avg       0.93      0.66      0.75      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming numeric_df is your dataset (already loaded)\n",
    "# Prepare the data\n",
    "X = numeric_df.drop(['FraudFound_P', 'PolicyNumber'], axis=1)\n",
    "y = numeric_df['FraudFound_P']\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define RandomUnderSampler\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Apply RandomUnderSampler to the training data to reduce the majority class size\n",
    "X_train_under, y_train_under = under_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(\"Class distribution after undersampling:\")\n",
    "print(pd.Series(y_train_under).value_counts())\n",
    "\n",
    "# Train and evaluate a RandomForest model on the original dataset (without undersampling)\n",
    "clf_original = RandomForestClassifier(random_state=42)\n",
    "clf_original.fit(X_train, y_train)\n",
    "y_pred_original = clf_original.predict(X_test)\n",
    "\n",
    "# Train and evaluate a RandomForest model on the undersampled dataset\n",
    "clf_under = RandomForestClassifier(random_state=42)\n",
    "clf_under.fit(X_train_under, y_train_under)\n",
    "y_pred_under = clf_under.predict(X_test)\n",
    "\n",
    "print(\"\\nPerformance on undersampled dataset:\")\n",
    "print(classification_report(y_test, y_pred_under, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
