{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('data/fraud_oracle_processed.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True, errors='ignore')\n",
    "\n",
    "# Define Categorical Columns for Encoding\n",
    "categorical_cols = [\n",
    "    'Month', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed',\n",
    "    'Fault', 'PolicyType', 'VehicleCategory', 'BasePolicy'\n",
    "]\n",
    "\n",
    "# One-Hot Encode Categorical Columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Convert Boolean Columns to Integers\n",
    "boolean_cols = ['MaritalStatus_Married', 'MaritalStatus_Single', 'MaritalStatus_Widow']\n",
    "df_encoded[boolean_cols] = df_encoded[boolean_cols].astype(int)\n",
    "\n",
    "# Separate Fraud and Non-Fraud Data\n",
    "df_fraud = df_encoded[df_encoded[\"FraudFound_P\"] == 1]\n",
    "df_no_fraud = df_encoded[df_encoded[\"FraudFound_P\"] == 0]\n",
    "\n",
    "# Split 15% Holdout for Final Evaluation\n",
    "df_fraud_train, df_fraud_holdout = train_test_split(\n",
    "    df_fraud, test_size=0.15, random_state=42, stratify=df_fraud[\"FraudFound_P\"]\n",
    ")\n",
    "\n",
    "df_no_fraud_train, df_no_fraud_holdout = train_test_split(\n",
    "    df_no_fraud, test_size=0.15, random_state=42, stratify=df_no_fraud[\"FraudFound_P\"]\n",
    ")\n",
    "\n",
    "# Combine Holdout Data for Final Evaluation\n",
    "df_holdout = pd.concat([df_fraud_holdout, df_no_fraud_holdout]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Standardize Entire Dataset Before Splitting\n",
    "scaler = StandardScaler()\n",
    "X = df_encoded.drop(columns=['FraudFound_P'])\n",
    "y = df_encoded['FraudFound_P']\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "df_scaled['FraudFound_P'] = y.values\n",
    "\n",
    "# Split Data for Hyperparameter Tuning (85% Train, 15% Holdout)\n",
    "df_train, df_holdout = train_test_split(df_scaled, test_size=0.15, random_state=42, stratify=df_scaled['FraudFound_P'])\n",
    "\n",
    "# Split df_train into X and y for Grid Search\n",
    "X_train_grid = df_train.drop(columns=['FraudFound_P'])\n",
    "y_train_grid = df_train['FraudFound_P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Params: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best XGBoost Params: {'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# # Logistic Regression Hyperparameters\n",
    "# lr_param_grid = {\n",
    "#     'C': [0.01, 0.1, 1, 10],\n",
    "#     'solver': ['saga', 'liblinear'],\n",
    "#     'max_iter': [1000, 5000]\n",
    "# }\n",
    "\n",
    "# lr_grid = GridSearchCV(LogisticRegression(random_state=42), param_grid=lr_param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "# lr_grid.fit(X_train_grid, y_train_grid)\n",
    "\n",
    "# # Best Parameters for Logistic Regression\n",
    "# best_lr_params = lr_grid.best_params_\n",
    "# print(f\"Best Logistic Regression Params: {best_lr_params}\")\n",
    "\n",
    "# Random Forest Hyperparameters\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "rf_grid.fit(X_train_grid, y_train_grid)\n",
    "\n",
    "# Best Parameters for Random Forest\n",
    "best_rf_params = rf_grid.best_params_\n",
    "print(f\"Best Random Forest Params: {best_rf_params}\")\n",
    "\n",
    "# XGBoost Hyperparameters\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(XGBClassifier(eval_metric='logloss', random_state=42), param_grid=xgb_param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "xgb_grid.fit(X_train_grid, y_train_grid)\n",
    "\n",
    "# Best Parameters for XGBoost\n",
    "best_xgb_params = xgb_grid.best_params_\n",
    "print(f\"Best XGBoost Params: {best_xgb_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 Balanced Datasets for Training\n",
    "datasets = []\n",
    "for i in range(10):\n",
    "    df_no_fraud_sampled = df_no_fraud_train.sample(n=len(df_fraud_train), random_state=i, replace=False)\n",
    "    df_combined = pd.concat([df_fraud_train, df_no_fraud_sampled]).sample(frac=1, random_state=i).reset_index(drop=True)\n",
    "    datasets.append(df_combined)\n",
    "\n",
    "# Standardize the Datasets\n",
    "scaled_datasets = []\n",
    "for df_combined in datasets:\n",
    "    X = df_combined.drop(columns=['FraudFound_P'])\n",
    "    y = df_combined['FraudFound_P']\n",
    "    \n",
    "    X_scaled = scaler.transform(X)\n",
    "    df_combined_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    df_combined_scaled['FraudFound_P'] = y.values\n",
    "    \n",
    "    scaled_datasets.append(df_combined_scaled)\n",
    "\n",
    "# Standardize Holdout Set\n",
    "X_holdout = df_holdout.drop(columns=['FraudFound_P'])\n",
    "y_holdout = df_holdout['FraudFound_P']\n",
    "\n",
    "X_holdout_scaled = scaler.transform(X_holdout)\n",
    "df_holdout_scaled = pd.DataFrame(X_holdout_scaled, columns=X_holdout.columns)\n",
    "df_holdout_scaled['FraudFound_P'] = y_holdout.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model using chosen Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_models, xgb_models = [], []\n",
    "\n",
    "for i, df_combined_scaled in enumerate(scaled_datasets):\n",
    "    X = df_combined_scaled.drop(columns=['FraudFound_P'])\n",
    "    y = df_combined_scaled['FraudFound_P']\n",
    "\n",
    "    \n",
    "    rf_model = RandomForestClassifier(**best_rf_params, random_state=42)\n",
    "    rf_model.fit(X, y)\n",
    "    rf_models.append(rf_model)\n",
    "    \n",
    "    xgb_model = XGBClassifier(**best_xgb_params, eval_metric='logloss', random_state=42)\n",
    "    xgb_model.fit(X, y)\n",
    "    xgb_models.append(xgb_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;xgb_model_1&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;logloss&#x27;,\n",
       "                                            feature_types=None,\n",
       "                                            feature_weights=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            intera...\n",
       "                                            feature_weights=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.2, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=6,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None, ...))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>VotingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>VotingClassifier(estimators=[(&#x27;xgb_model_1&#x27;,\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;logloss&#x27;,\n",
       "                                            feature_types=None,\n",
       "                                            feature_weights=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            intera...\n",
       "                                            feature_weights=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.2, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=6,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None, ...))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb_model_1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb_model_2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb_model_3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb_model_4</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb_model_5</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb_model_6</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb_model_7</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb_model_8</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb_model_9</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb_model_10</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('xgb_model_1',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric='logloss',\n",
       "                                            feature_types=None,\n",
       "                                            feature_weights=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            intera...\n",
       "                                            feature_weights=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.2, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=6,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None, ...))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Voting Ensembles for Each Model Type\n",
    "rf_model_list = [(f'rf_model_{i+1}', rf_models[i]) for i in range(10)]\n",
    "xgb_model_list = [(f'xgb_model_{i+1}', xgb_models[i]) for i in range(10)]\n",
    "\n",
    "# Voting Classifiers for Each Model Type\n",
    "voting_model_rf = VotingClassifier(estimators=rf_model_list, voting='soft')\n",
    "voting_model_xgb = VotingClassifier(estimators=xgb_model_list, voting='soft')\n",
    "\n",
    "# Prepare Final Dataset for Voting Models\n",
    "final_X = scaled_datasets[-1].drop(columns=['FraudFound_P'])\n",
    "final_y = scaled_datasets[-1]['FraudFound_P']\n",
    "\n",
    "# Fit Voting Models\n",
    "voting_model_rf.fit(final_X, final_y)\n",
    "voting_model_xgb.fit(final_X, final_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Ensemble Classification Report on Holdout Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.77      2175\n",
      "           1       0.12      0.82      0.22       138\n",
      "\n",
      "    accuracy                           0.65      2313\n",
      "   macro avg       0.55      0.73      0.49      2313\n",
      "weighted avg       0.93      0.65      0.74      2313\n",
      "\n",
      "XGBoost Ensemble Classification Report on Holdout Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71      2175\n",
      "           1       0.12      0.96      0.21       138\n",
      "\n",
      "    accuracy                           0.58      2313\n",
      "   macro avg       0.56      0.76      0.46      2313\n",
      "weighted avg       0.94      0.58      0.68      2313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Individual Voting Models on Holdout\n",
    "X_holdout_final = df_holdout_scaled.drop(columns=['FraudFound_P'])\n",
    "y_holdout_final = df_holdout_scaled['FraudFound_P']\n",
    "\n",
    "y_pred_rf = voting_model_rf.predict(X_holdout_final)\n",
    "print(\"Random Forest Ensemble Classification Report on Holdout Data:\")\n",
    "print(classification_report(y_holdout_final, y_pred_rf))\n",
    "\n",
    "y_pred_xgb = voting_model_xgb.predict(X_holdout_final)\n",
    "print(\"XGBoost Ensemble Classification Report on Holdout Data:\")\n",
    "print(classification_report(y_holdout_final, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Ensemble Model (LR + RF + XGB) Classification Report on Holdout Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.72      2175\n",
      "           1       0.12      0.96      0.22       138\n",
      "\n",
      "    accuracy                           0.58      2313\n",
      "   macro avg       0.56      0.76      0.47      2313\n",
      "weighted avg       0.94      0.58      0.69      2313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Ensemble of All Models (LR + RF + XGB)\n",
    "all_models_list =  rf_model_list + xgb_model_list\n",
    "final_voting_model = VotingClassifier(estimators=all_models_list, voting='soft')\n",
    "\n",
    "# Fit Final Voting Model on Full 85% Data\n",
    "final_voting_model.fit(final_X, final_y)\n",
    "\n",
    "# Evaluate Final Voting Model on Holdout Data\n",
    "y_pred_final = final_voting_model.predict(X_holdout_final)\n",
    "print(\"Final Ensemble Model (LR + RF + XGB) Classification Report on Holdout Data:\")\n",
    "print(classification_report(y_holdout_final, y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Ensemble Classification Report on Holdout Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.59      0.74      2175\n",
      "           1       0.11      0.83      0.20       138\n",
      "\n",
      "    accuracy                           0.61      2313\n",
      "   macro avg       0.55      0.71      0.47      2313\n",
      "weighted avg       0.93      0.61      0.71      2313\n",
      "\n",
      "XGBoost Ensemble Classification Report on Holdout Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.58      0.73      2175\n",
      "           1       0.12      0.91      0.21       138\n",
      "\n",
      "    accuracy                           0.60      2313\n",
      "   macro avg       0.56      0.75      0.47      2313\n",
      "weighted avg       0.94      0.60      0.70      2313\n",
      "\n",
      "Final Ensemble Model (RF + XGB) Classification Report on Holdout Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.57      0.73      2175\n",
      "           1       0.12      0.92      0.21       138\n",
      "\n",
      "    accuracy                           0.59      2313\n",
      "   macro avg       0.56      0.75      0.47      2313\n",
      "weighted avg       0.94      0.59      0.70      2313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv('data/fraud_oracle_processed.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True, errors='ignore')\n",
    "\n",
    "# Define Top Selected Features\n",
    "top_features = [\n",
    "    'Fault_Third Party',                  # Encoded version of 'Fault'\n",
    "    'VehicleCategory_Sport',              # Encoded version of 'VehicleCategory'\n",
    "    'PolicyType_Sedan - Collision',       # Example of PolicyType (you may want to select more)\n",
    "    'PriceToAgeRatio',                     # Derived feature added manually\n",
    "    'AgeOfVehicle',                        # Numeric feature\n",
    "    'AccidentArea_Urban',                  # Encoded version of 'AccidentArea'\n",
    "    'MonthClaimed',                        # Kept as original (not one-hot encoded)\n",
    "    'AddressChange_Claim',                 # Kept as original (not one-hot encoded)\n",
    "    'VehiclePrice',                        # Numeric feature\n",
    "    'BasePolicy_Collision'                 # Encoded version of 'BasePolicy'\n",
    "]\n",
    "\n",
    "\n",
    "# One-Hot Encode Categorical Columns\n",
    "df_encoded = pd.get_dummies(df, columns=['Month', 'DayOfWeek', 'Make', 'AccidentArea',\n",
    "                                          'DayOfWeekClaimed', 'Fault', 'PolicyType',\n",
    "                                          'VehicleCategory', 'BasePolicy'], drop_first=True)\n",
    "\n",
    "# Convert Boolean Columns to Integers\n",
    "boolean_cols = ['MaritalStatus_Married', 'MaritalStatus_Single', 'MaritalStatus_Widow']\n",
    "df_encoded[boolean_cols] = df_encoded[boolean_cols].astype(int)\n",
    "\n",
    "# Add PriceToAgeRatio Feature\n",
    "df_encoded['PriceToAgeRatio'] = df_encoded['VehiclePrice'] / (df_encoded['AgeOfVehicle'] + 1)\n",
    "\n",
    "# Filter Selected Features + Target Column\n",
    "df_selected = df_encoded[top_features + ['FraudFound_P']]\n",
    "\n",
    "# Split Fraud and Non-Fraud Data\n",
    "df_fraud = df_selected[df_selected[\"FraudFound_P\"] == 1]\n",
    "df_no_fraud = df_selected[df_selected[\"FraudFound_P\"] == 0]\n",
    "\n",
    "# Split 15% Holdout for Final Evaluation\n",
    "df_fraud_train, df_fraud_holdout = train_test_split(\n",
    "    df_fraud, test_size=0.15, random_state=42, stratify=df_fraud[\"FraudFound_P\"])\n",
    "\n",
    "df_no_fraud_train, df_no_fraud_holdout = train_test_split(\n",
    "    df_no_fraud, test_size=0.15, random_state=42, stratify=df_no_fraud[\"FraudFound_P\"])\n",
    "\n",
    "# Combine Holdout Data for Final Evaluation\n",
    "df_holdout = pd.concat([df_fraud_holdout, df_no_fraud_holdout]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Standardize Selected Features Before Splitting\n",
    "scaler = StandardScaler()\n",
    "X = df_selected.drop(columns=['FraudFound_P'])\n",
    "y = df_selected['FraudFound_P']\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "df_scaled['FraudFound_P'] = y.values\n",
    "\n",
    "# Split Data for Hyperparameter Tuning (85% Train, 15% Holdout)\n",
    "df_train, df_holdout = train_test_split(df_scaled, test_size=0.15, random_state=42, stratify=df_scaled['FraudFound_P'])\n",
    "\n",
    "# Split df_train into X and y for Grid Search\n",
    "X_train_grid = df_train.drop(columns=['FraudFound_P'])\n",
    "y_train_grid = df_train['FraudFound_P']\n",
    "\n",
    "# Logistic Regression Hyperparameters\n",
    "lr_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['saga', 'liblinear'],\n",
    "    'max_iter': [1000, 5000]\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(LogisticRegression(random_state=42), param_grid=lr_param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "lr_grid.fit(X_train_grid, y_train_grid)\n",
    "best_lr_params = lr_grid.best_params_\n",
    "\n",
    "# Random Forest Hyperparameters\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=rf_param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "rf_grid.fit(X_train_grid, y_train_grid)\n",
    "best_rf_params = rf_grid.best_params_\n",
    "\n",
    "# XGBoost Hyperparameters\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(XGBClassifier(eval_metric='logloss', random_state=42), param_grid=xgb_param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "xgb_grid.fit(X_train_grid, y_train_grid)\n",
    "best_xgb_params = xgb_grid.best_params_\n",
    "\n",
    "# Generate 10 Balanced Datasets for Training\n",
    "datasets = []\n",
    "for i in range(10):\n",
    "    df_no_fraud_sampled = df_no_fraud_train.sample(n=len(df_fraud_train), random_state=i, replace=False)\n",
    "    df_combined = pd.concat([df_fraud_train, df_no_fraud_sampled]).sample(frac=1, random_state=i).reset_index(drop=True)\n",
    "    datasets.append(df_combined)\n",
    "\n",
    "# Standardize the Datasets\n",
    "scaled_datasets = []\n",
    "for df_combined in datasets:\n",
    "    X = df_combined.drop(columns=['FraudFound_P'])\n",
    "    y = df_combined['FraudFound_P']\n",
    "    X_scaled = scaler.transform(X)\n",
    "    df_combined_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    df_combined_scaled['FraudFound_P'] = y.values\n",
    "    scaled_datasets.append(df_combined_scaled)\n",
    "\n",
    "# Standardize Holdout Set\n",
    "X_holdout = df_holdout.drop(columns=['FraudFound_P'])\n",
    "y_holdout = df_holdout['FraudFound_P']\n",
    "\n",
    "X_holdout_scaled = scaler.transform(X_holdout)\n",
    "df_holdout_scaled = pd.DataFrame(X_holdout_scaled, columns=X_holdout.columns)\n",
    "df_holdout_scaled['FraudFound_P'] = y_holdout.values\n",
    "\n",
    "# Train Models and Create Voting Ensembles\n",
    "rf_models, xgb_models = [], []\n",
    "for i, df_combined_scaled in enumerate(scaled_datasets):\n",
    "    X = df_combined_scaled.drop(columns=['FraudFound_P'])\n",
    "    y = df_combined_scaled['FraudFound_P']\n",
    "    \n",
    "    rf_model = RandomForestClassifier(**best_rf_params, random_state=42)\n",
    "    rf_model.fit(X, y)\n",
    "    rf_models.append(rf_model)\n",
    "    \n",
    "    xgb_model = XGBClassifier(**best_xgb_params, eval_metric='logloss', random_state=42)\n",
    "    xgb_model.fit(X, y)\n",
    "    xgb_models.append(xgb_model)\n",
    "\n",
    "rf_model_list = [(f'rf_model_{i+1}', rf_models[i]) for i in range(10)]\n",
    "xgb_model_list = [(f'xgb_model_{i+1}', xgb_models[i]) for i in range(10)]\n",
    "\n",
    "voting_model_rf = VotingClassifier(estimators=rf_model_list, voting='soft')\n",
    "voting_model_xgb = VotingClassifier(estimators=xgb_model_list, voting='soft')\n",
    "\n",
    "final_X = scaled_datasets[-1].drop(columns=['FraudFound_P'])\n",
    "final_y = scaled_datasets[-1]['FraudFound_P']\n",
    "\n",
    "voting_model_rf.fit(final_X, final_y)\n",
    "voting_model_xgb.fit(final_X, final_y)\n",
    "\n",
    "# Evaluate Individual Voting Models on Holdout\n",
    "X_holdout_final = df_holdout_scaled.drop(columns=['FraudFound_P'])\n",
    "y_holdout_final = df_holdout_scaled['FraudFound_P']\n",
    "\n",
    "\n",
    "y_pred_rf = voting_model_rf.predict(X_holdout_final)\n",
    "print(\"Random Forest Ensemble Classification Report on Holdout Data:\")\n",
    "print(classification_report(y_holdout_final, y_pred_rf))\n",
    "\n",
    "y_pred_xgb = voting_model_xgb.predict(X_holdout_final)\n",
    "print(\"XGBoost Ensemble Classification Report on Holdout Data:\")\n",
    "print(classification_report(y_holdout_final, y_pred_xgb))\n",
    "\n",
    "# Final Ensemble of All Models (LR + RF + XGB)\n",
    "all_models_list =  rf_model_list + xgb_model_list\n",
    "final_voting_model = VotingClassifier(estimators=all_models_list, voting='soft')\n",
    "\n",
    "# Fit Final Voting Model on Full 85% Data\n",
    "final_voting_model.fit(final_X, final_y)\n",
    "\n",
    "# Evaluate Final Voting Model on Holdout Data\n",
    "y_pred_final = final_voting_model.predict(X_holdout_final)\n",
    "print(\"Final Ensemble Model (RF + XGB) Classification Report on Holdout Data:\")\n",
    "print(classification_report(y_holdout_final, y_pred_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.4088134862627753\n",
      "Final Classification Report on Holdout Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.74      0.82      2175\n",
      "           1       0.78      0.92      0.85      2174\n",
      "\n",
      "    accuracy                           0.83      4349\n",
      "   macro avg       0.84      0.83      0.83      4349\n",
      "weighted avg       0.84      0.83      0.83      4349\n",
      "\n",
      "Calibrated Model Classification Report on Holdout Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.74      0.82      2175\n",
      "           1       0.78      0.92      0.85      2174\n",
      "\n",
      "    accuracy                           0.83      4349\n",
      "   macro avg       0.84      0.83      0.83      4349\n",
      "weighted avg       0.84      0.83      0.83      4349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv('data/fraud_oracle_processed.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True, errors='ignore')\n",
    "\n",
    "# Define Top Selected Features\n",
    "top_features = [\n",
    "    'Fault_Third Party', 'VehicleCategory_Sport', 'PolicyType_Sedan - Collision',\n",
    "    'PriceToAgeRatio', 'AgeOfVehicle', 'AccidentArea_Urban',\n",
    "    'MonthClaimed', 'AddressChange_Claim', 'VehiclePrice', 'BasePolicy_Collision'\n",
    "]\n",
    "\n",
    "# One-Hot Encode Categorical Columns\n",
    "df_encoded = pd.get_dummies(df, columns=['Month', 'DayOfWeek', 'Make', 'AccidentArea',\n",
    "                                          'DayOfWeekClaimed', 'Fault', 'PolicyType',\n",
    "                                          'VehicleCategory', 'BasePolicy'], drop_first=True)\n",
    "\n",
    "# Convert Boolean Columns to Integers\n",
    "boolean_cols = ['MaritalStatus_Married', 'MaritalStatus_Single', 'MaritalStatus_Widow']\n",
    "df_encoded[boolean_cols] = df_encoded[boolean_cols].astype(int)\n",
    "\n",
    "# Add PriceToAgeRatio Feature\n",
    "df_encoded['PriceToAgeRatio'] = df_encoded['VehiclePrice'] / (df_encoded['AgeOfVehicle'] + 1)\n",
    "\n",
    "# Filter Selected Features + Target Column\n",
    "df_selected = df_encoded[top_features + ['FraudFound_P']]\n",
    "\n",
    "# Split Data for Resampling\n",
    "X = df_selected.drop(columns=['FraudFound_P'])\n",
    "y = df_selected['FraudFound_P']\n",
    "\n",
    "# Apply SMOTE + Tomek Links\n",
    "tomek = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = tomek.fit_resample(X, y)\n",
    "\n",
    "# Split Data for Training and Holdout\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X_resampled, y_resampled, test_size=0.15, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_holdout_scaled = scaler.transform(X_holdout)\n",
    "\n",
    "# Train Isolation Forest for Anomaly Detection\n",
    "iso_forest = IsolationForest(contamination=0.02, random_state=42)\n",
    "iso_forest.fit(X_train_scaled)\n",
    "\n",
    "# Generate Anomaly Scores\n",
    "X_train['anomaly_score'] = iso_forest.decision_function(X_train_scaled)\n",
    "X_holdout['anomaly_score'] = iso_forest.decision_function(X_holdout_scaled)\n",
    "\n",
    "# Prepare Final Features After Adding Anomaly Score\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_holdout_scaled = scaler.transform(X_holdout)\n",
    "\n",
    "# Train Base Models\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Fit Models\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Create Stacking Model\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_model),\n",
    "        ('rf', rf_model),\n",
    "        ('xgb', xgb_model)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "# Fit Stacking Model\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Fine-Tune Classification Threshold\n",
    "y_probs = stacked_model.predict_proba(X_holdout_scaled)[:, 1]\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_holdout, y_probs)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Apply Optimal Threshold\n",
    "y_pred_final = (y_probs >= optimal_threshold).astype(int)\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "print(\"Final Classification Report on Holdout Data:\")\n",
    "print(classification_report(y_holdout, y_pred_final))\n",
    "\n",
    "# Calibrate Model Probabilities\n",
    "calibrated_model = CalibratedClassifierCV(stacked_model, method='isotonic', cv=5)\n",
    "calibrated_model.fit(X_train_scaled, y_train)\n",
    "y_probs_calibrated = calibrated_model.predict_proba(X_holdout_scaled)[:, 1]\n",
    "\n",
    "# Final Predictions with Calibrated Model\n",
    "y_pred_calibrated = (y_probs_calibrated >= optimal_threshold).astype(int)\n",
    "print(\"Calibrated Model Classification Report on Holdout Data:\")\n",
    "print(classification_report(y_holdout, y_pred_calibrated))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply SMOTE and Tomek to balance the classes as  form or resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution After Resampling: Counter({0: 14495, 1: 14495})\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Apply SMOTE and Tomek to balance classes as resampling methods.\n",
    "Use PyTorch for autoencoder to detect anomalies.\n",
    "Train base models (Logistic Regression, Random Forest, XGBoost) and stack them using LGBM as the meta-learner.\n",
    "Fine-tune classification threshold based on F1 score.\n",
    "'''\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv('data/fraud_oracle_processed.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True, errors='ignore')\n",
    "\n",
    "# Define Top Selected Features\n",
    "top_features = [\n",
    "    'Fault_Third Party', 'VehicleCategory_Sport', 'PolicyType_Sedan - Collision',\n",
    "    'PriceToAgeRatio', 'AgeOfVehicle', 'AccidentArea_Urban',\n",
    "    'MonthClaimed', 'AddressChange_Claim', 'VehiclePrice', 'BasePolicy_Collision'\n",
    "]\n",
    "\n",
    "# One-Hot Encode Categorical Columns\n",
    "df_encoded = pd.get_dummies(df, columns=['Month', 'DayOfWeek', 'Make', 'AccidentArea',\n",
    "                                          'DayOfWeekClaimed', 'Fault', 'PolicyType',\n",
    "                                          'VehicleCategory', 'BasePolicy'], drop_first=True)\n",
    "\n",
    "# Convert Boolean Columns to Integers\n",
    "boolean_cols = ['MaritalStatus_Married', 'MaritalStatus_Single', 'MaritalStatus_Widow']\n",
    "df_encoded[boolean_cols] = df_encoded[boolean_cols].astype(int)\n",
    "\n",
    "# Add PriceToAgeRatio Feature\n",
    "df_encoded['PriceToAgeRatio'] = df_encoded['VehiclePrice'] / (df_encoded['AgeOfVehicle'] + 1)\n",
    "\n",
    "# Filter Selected Features + Target Column\n",
    "df_selected = df_encoded[top_features + ['FraudFound_P']]\n",
    "\n",
    "# Split Data for Resampling\n",
    "X = df_selected.drop(columns=['FraudFound_P'])\n",
    "y = df_selected['FraudFound_P']\n",
    "\n",
    "# Apply SMOTE + Tomek Links\n",
    "tomek = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = tomek.fit_resample(X, y)\n",
    "\n",
    "# Check class balance after resampling\n",
    "print(f\"Class Distribution After Resampling: {Counter(y_resampled)}\")\n",
    "\n",
    "# Split Data for Training and Holdout\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X_resampled, y_resampled, test_size=0.15, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_holdout_scaled = scaler.transform(X_holdout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PyTorch Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Prepare Data for PyTorch\n",
    "def to_tensor(data):\n",
    "    return torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "X_train_tensor = to_tensor(X_train_scaled)\n",
    "X_holdout_tensor = to_tensor(X_holdout_scaled)\n",
    "\n",
    "# Convert y_train to NumPy Array for Indexing\n",
    "y_train_np = y_train.to_numpy()\n",
    "\n",
    "# Train PyTorch Autoencoder\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "autoencoder = Autoencoder(input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "# Train Autoencoder on Normal Data Only\n",
    "normal_data = X_train_tensor[y_train_np == 0]\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = autoencoder(normal_data)\n",
    "    loss = criterion(outputs, normal_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Reconstruction Error as Anomaly Score\n",
    "def compute_reconstruction_error(autoencoder, data):\n",
    "    with torch.no_grad():\n",
    "        reconstructed = autoencoder(data)\n",
    "        mse = torch.mean((data - reconstructed) ** 2, axis=1)\n",
    "    return mse.numpy()\n",
    "\n",
    "reconstruction_error_train = compute_reconstruction_error(autoencoder, X_train_tensor)\n",
    "reconstruction_error_holdout = compute_reconstruction_error(autoencoder, X_holdout_tensor)\n",
    "\n",
    "# Add Anomaly Scores\n",
    "X_train_scaled = np.hstack((X_train_scaled, reconstruction_error_train.reshape(-1, 1)))\n",
    "X_holdout_scaled = np.hstack((X_holdout_scaled, reconstruction_error_holdout.reshape(-1, 1)))\n",
    "\n",
    "# Define Updated Feature Names\n",
    "feature_names = list(X_train.columns) + ['anomaly_score']\n",
    "\n",
    "# Convert Scaled Arrays Back to DataFrame\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "X_holdout_scaled_df = pd.DataFrame(X_holdout_scaled, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names Before Training:\n",
      "['Fault_Third Party', 'VehicleCategory_Sport', 'PolicyType_Sedan - Collision', 'PriceToAgeRatio', 'AgeOfVehicle', 'AccidentArea_Urban', 'MonthClaimed', 'AddressChange_Claim', 'VehiclePrice', 'BasePolicy_Collision', 'anomaly_score']\n",
      "Feature Names Before Prediction:\n",
      "['Fault_Third Party', 'VehicleCategory_Sport', 'PolicyType_Sedan - Collision', 'PriceToAgeRatio', 'AgeOfVehicle', 'AccidentArea_Urban', 'MonthClaimed', 'AddressChange_Claim', 'VehiclePrice', 'BasePolicy_Collision', 'anomaly_score']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.4744091071907198\n",
      "Final Classification Report on Holdout Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83      2175\n",
      "           1       0.80      0.91      0.85      2174\n",
      "\n",
      "    accuracy                           0.84      4349\n",
      "   macro avg       0.85      0.84      0.84      4349\n",
      "weighted avg       0.85      0.84      0.84      4349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold for Calibrated Model: 0.41052093245125787\n",
      "Calibrated Model Classification Report on Holdout Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82      2175\n",
      "           1       0.78      0.94      0.85      2174\n",
      "\n",
      "    accuracy                           0.84      4349\n",
      "   macro avg       0.85      0.84      0.84      4349\n",
      "weighted avg       0.85      0.84      0.84      4349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\xutia\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train Base Models\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Check Feature Names Before Fitting\n",
    "print(f\"Feature Names Before Training:\\n{X_train_scaled_df.columns.tolist()}\")\n",
    "\n",
    "# Check Feature Names Before Prediction\n",
    "print(f\"Feature Names Before Prediction:\\n{X_holdout_scaled_df.columns.tolist()}\")\n",
    "\n",
    "# Fit Models\n",
    "lr_model.fit(X_train_scaled_df, y_train)\n",
    "rf_model.fit(X_train_scaled_df, y_train)\n",
    "xgb_model.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "# Create Stacking Model with LGBM as Meta-Learner\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_model),\n",
    "        ('rf', rf_model),\n",
    "        ('xgb', xgb_model)\n",
    "    ],\n",
    "    final_estimator=LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42, verbose=-1)\n",
    ")\n",
    "\n",
    "# Fit Stacking Model\n",
    "stacked_model.fit(X_train_scaled_df, y_train)\n",
    "\n",
    "# Fine-Tune Classification Threshold\n",
    "y_probs = stacked_model.predict_proba(X_holdout_scaled_df)[:, 1]\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_holdout, y_probs)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Apply Optimal Threshold\n",
    "y_pred_final = (y_probs >= optimal_threshold).astype(int)\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "print(\"Final Classification Report on Holdout Data:\")\n",
    "print(classification_report(y_holdout, y_pred_final))\n",
    "\n",
    "# Calibrate Model Probabilities\n",
    "calibrated_model = CalibratedClassifierCV(stacked_model, method='isotonic', cv=5)\n",
    "calibrated_model.fit(X_train_scaled_df, y_train)\n",
    "y_probs_calibrated = calibrated_model.predict_proba(X_holdout_scaled_df)[:, 1]\n",
    "\n",
    "# Recalculate Optimal Threshold for Calibrated Model\n",
    "precisions_cal, recalls_cal, thresholds_cal = precision_recall_curve(y_holdout, y_probs_calibrated)\n",
    "f1_scores_cal = 2 * (precisions_cal * recalls_cal) / (precisions_cal + recalls_cal)\n",
    "optimal_idx_cal = np.argmax(f1_scores_cal)\n",
    "optimal_threshold_cal = thresholds_cal[optimal_idx_cal]\n",
    "\n",
    "# Apply New Optimal Threshold for Calibrated Model\n",
    "y_pred_calibrated = (y_probs_calibrated >= optimal_threshold_cal).astype(int)\n",
    "print(f\"Optimal Threshold for Calibrated Model: {optimal_threshold_cal}\")\n",
    "print(\"Calibrated Model Classification Report on Holdout Data:\")\n",
    "print(classification_report(y_holdout, y_pred_calibrated))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
